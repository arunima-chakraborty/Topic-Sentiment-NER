{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23302d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn as nn\n",
    "from transformers import DistilBertTokenizerFast, TrainingArguments, Trainer, EarlyStoppingCallback, BitsAndBytesConfig,AutoModel, AutoTokenizer,AdamW\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score as sk_accuracy, f1_score as sk_f1\n",
    "from seqeval.metrics import accuracy_score, f1_score \n",
    "import numpy as np\n",
    "import contractions\n",
    "import bitsandbytes as bnb\n",
    "from data_class import CustomNERTopicDataset\n",
    "from model_class_lora import MultiTaskModel \n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "MAX_LEN = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"input_ids\": torch.stack([x[\"input_ids\"] for x in batch]),\n",
    "        \"attention_mask\": torch.stack([x[\"attention_mask\"] for x in batch]),\n",
    "        \"topic_labels\": torch.stack([x[\"topic_labels\"] for x in batch]),\n",
    "        \"ner_labels\": torch.stack([x[\"ner_labels\"] for x in batch]),\n",
    "        \"sentiment\": torch.stack([x[\"sentiment\"] for x in batch]),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0930bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2ner_label = {\n",
    "            0:'O',\n",
    "            1:'PER',\n",
    "            2:'LOC',\n",
    "            3:'ORG',\n",
    "            4:'MISC'\n",
    "            }\n",
    "        \n",
    "id2bio_label = {\n",
    "            0:'O',\n",
    "            1:'B',\n",
    "            2:'I',\n",
    "            3:'E',\n",
    "            4:'S'\n",
    "        }\n",
    "id2sentiment_label = {\n",
    "            0:'negative',\n",
    "            1:'neutral',\n",
    "            2:'positive'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a589a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(p):\n",
    "    predictions = p.predictions\n",
    "    labels = p.label_ids\n",
    "\n",
    "    \n",
    "    if len(predictions) not in {2, 3}:\n",
    "        raise ValueError(f\"Unexpected number of prediction outputs: {len(predictions)}\")\n",
    "\n",
    "    topic_preds, ner_preds = predictions[:2]\n",
    "    topic_labels, ner_labels = labels[:2]\n",
    "\n",
    "    sentiment_preds = predictions[2] if len(predictions) == 3 else None\n",
    "    sentiment_labels = labels[2] if len(labels) == 3 else None\n",
    "\n",
    "    \n",
    "    if topic_preds.ndim == 3:\n",
    "        topic_preds = np.argmax(topic_preds, axis=-1)\n",
    "    if ner_preds.ndim == 3:\n",
    "        ner_preds = np.argmax(ner_preds, axis=-1)\n",
    "    if sentiment_preds is not None and sentiment_preds.ndim == 2:\n",
    "        sentiment_preds = np.argmax(sentiment_preds, axis=-1)\n",
    "\n",
    "    def convert_to_labels(preds, labels, id2label):\n",
    "        return [\n",
    "            [id2label[p] for p, l in zip(pred_seq, label_seq) if l != -100]\n",
    "            for pred_seq, label_seq in zip(preds, labels)\n",
    "        ]\n",
    "\n",
    "    \n",
    "    topic_preds_str = convert_to_labels(topic_preds, topic_labels, id2bio_label)\n",
    "    topic_labels_str = convert_to_labels(topic_labels, topic_labels, id2bio_label)\n",
    "\n",
    "    ner_preds_str = convert_to_labels(ner_preds, ner_labels, id2ner_label)\n",
    "    ner_labels_str = convert_to_labels(ner_labels, ner_labels, id2ner_label)\n",
    "\n",
    "   \n",
    "    topic_f1 = f1_score(topic_labels_str, topic_preds_str)\n",
    "    topic_acc = accuracy_score(topic_labels_str, topic_preds_str)\n",
    "\n",
    "    \n",
    "    ner_f1 = f1_score(ner_labels_str, ner_preds_str)\n",
    "    ner_acc = accuracy_score(ner_labels_str, ner_preds_str)\n",
    "\n",
    "    \n",
    "    sentiment_acc = sentiment_f1 = None\n",
    "    if sentiment_preds is not None and sentiment_labels is not None:\n",
    "        sentiment_acc = sk_accuracy(sentiment_labels, sentiment_preds)\n",
    "        sentiment_f1 = sk_f1(sentiment_labels, sentiment_preds, average='weighted')\n",
    "\n",
    "    \n",
    "    metrics = {\n",
    "        \"topic_f1\": topic_f1,\n",
    "        \"topic_accuracy\": topic_acc,\n",
    "        \"ner_f1\": ner_f1,\n",
    "        \"ner_accuracy\": ner_acc,\n",
    "    }\n",
    "\n",
    "    if sentiment_acc is not None:\n",
    "        metrics.update({\n",
    "            \"sentiment_accuracy\": sentiment_acc,\n",
    "            \"sentiment_f1\": sentiment_f1\n",
    "        })\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69fc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/data/train_data.csv\")\n",
    "data = data[[\"text\", \"topics\", \"sentiment\", \"ner\"]]\n",
    "data.dropna(subset=[\"text\"],inplace=True)\n",
    "\n",
    "\n",
    "n = int(0.8*len(data))\n",
    "train_dataset = CustomNERTopicDataset(data[:n])\n",
    "eval_dataset = CustomNERTopicDataset(data[n:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    per_device_train_batch_size=200,\n",
    "    per_device_eval_batch_size=200,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    learning_rate=2e-6,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model=\"topic_accuracy\",\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1000,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=False,\n",
    "    bf16=False, \n",
    "    overwrite_output_dir=True,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "model = MultiTaskModel().to(device=device)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizer = AdamW(model.parameters(), \n",
    "                  lr=1e-4,\n",
    "                  no_deprecation_warning=True),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "torch.save(model.state_dict(), \"./topic_sentiment_lora-config.bin\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8239c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = \"multilingual-model.bin\"\n",
    "    encodings = tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=128,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    tokens = encodings[\"input_ids\"].squeeze().tolist()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokens)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=encodings[\"input_ids\"],\n",
    "            attention_mask=encodings[\"attention_mask\"]\n",
    "        )\n",
    "        \n",
    "\n",
    "    topic_logits = outputs.get(\"topic_logits\")\n",
    "    sentiment_logits = outputs.get(\"sentiment_logits\")\n",
    "    ner_logits = outputs.get(\"ner_logits\")\n",
    "    \n",
    "\n",
    "    if topic_logits is None or sentiment_logits is None or ner_logits is None:\n",
    "        raise ValueError(\"Model output does not contain the expected logits for topic, sentiment, or NER.\")\n",
    "\n",
    "    topic_predictions = torch.argmax(topic_logits, dim=-1).squeeze().to(device).tolist()\n",
    "    sentiment_prediction = torch.argmax(sentiment_logits).to(device).item() \n",
    "    ner_predictions = torch.argmax(ner_logits, dim=-1).squeeze().to(device).tolist()\n",
    "\n",
    "    return tokens,topic_predictions, sentiment_prediction, ner_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"I tried the iphone pro. Its awesome\",\n",
    "        \"Sarah said her calls are getting dropped or going to voicemail\",\n",
    "        \"The ratings have gone down, their service is not good anymore\",\n",
    "        \"Hold on! Okay would you tell her I called? Yeah. This is Martina. Call me back on 99999999\"\n",
    "]\n",
    "for text in texts:\n",
    "    print(\"Text:\", text)    \n",
    "    tokens, topic_predictions, sentiment_prediction, ner_predictions = predictions(text)\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in [\"[CLS]\",\"[SEP]\",\"[PAD]\",\"[UNK]\"]:\n",
    "            print(f\"{tokens[i]} : {id2bio_label[topic_predictions[i]]}-TOPIC : {id2ner_label[ner_predictions[i]]}\")\n",
    "    print(id2sentiment_label[sentiment_prediction])\n",
    "    print(\"=====================================================================\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arunima-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
